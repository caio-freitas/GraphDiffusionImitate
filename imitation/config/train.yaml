defaults:
  - _self_
  - task: lift_graph
  - policy: graph_ddpm_policy

output_dir: ./outputs
# on evaluating, for environment wrapper
render: False
output_video: True

pred_horizon: 16
obs_horizon: 4
action_horizon: 2
# Training parameters
num_epochs: 500
val_fraction: 0.1
seed: 0
load_ckpt: False # start training from scratch

env_runner: ${task.env_runner}

agent:
  _target_: imitation.agent.robomimic_lowdim_agent.RobomimicLowdimAgent

# Disable evaluation 
# eval_params: "disabled"
max_steps: ${task.max_steps}

# Evaluation during training
eval_params:
  eval_every: 10 # evaluate every 50 epochs
  val_every: 1
  task: ${task}
  policy: ${policy}
  render: False
  output_video: True
  load_ckpt: True # always load for evaluation

  num_episodes: 50
  max_steps: ${task.max_steps}
  output_dir: ./outputs


  pred_horizon: ${pred_horizon}
  action_horizon: ${action_horizon}
  obs_horizon: ${obs_horizon}


  env_runner: ${task.env_runner}

  seed: 0

  agent: ${agent}
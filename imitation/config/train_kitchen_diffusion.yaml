output_dir: ./output

# Environment
obs_dim: 60
action_dim: 9
pred_horizon: 4 # > obs_horizon + action_horizon
obs_horizon: 1
action_horizon: 1


n_obs_steps: ${obs_horizon}
n_action_steps: ${action_horizon}

# Training parameters
num_epochs: 1000
model_path: ./weights/kitchen_diffusion_last.pt



env_runner: 
  _target_: imitation.env_runner.robomimic_lowdim_runner.RobomimicEnvRunner
  output_dir: ${output_dir}
  env:
    _target_: imitation.env.robomimic_lowdim_wrapper.RobomimicLowdimWrapper
    task: "Lift"

policy:
  _target_: imitation.policy.diffusion_policy.DiffusionUnet1DPolicy
  obs_dim: ${obs_dim}
  action_dim: ${action_dim}
  pred_horizon: ${pred_horizon}
  obs_horizon: ${obs_horizon}
  action_horizon: ${action_horizon}
  num_diffusion_iters: 100
  ckpt_path: ./weights/kitchen_diffusion.pt
  # Diffusion Policy Dataset
  dataset:
    _target_: diffusion_policy.dataset.kitchen_lowdim_dataset.KitchenLowdimDataset
    dataset_dir: ../diffusion_policy/data/kitchen/
    horizon: ${pred_horizon}
    pad_before: ${eval:'${n_obs_steps}-1'}
    pad_after: ${eval:'${n_action_steps}-1'}
    seed: 42
    val_ratio: 0.02
  # Relay Policy Dataset
  # dataset:
  #   _target_: diffusion_policy.dataset.kitchen_mjl_lowdim_dataset.KitchenMjlLowdimDataset
  #   dataset_dir: ./data/kitchen_demos_multitask
  #   horizon: ${pred_horizon}
  #   pad_before: ${eval:'${n_obs_steps}-1'}
  #   pad_after: ${eval:'${n_action_steps}-1'}
  #   robot_noise_ratio: 0.0
  #   seed: 42
  #   val_ratio: 0.02


  # ckpt_path: ${model_path}


agent:
  _target_: imitation.agent.robomimic_lowdim_agent.RobomimicLowdimAgent
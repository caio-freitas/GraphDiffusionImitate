output_dir: ./output

# Environment
obs_dim: 60
action_dim: 9
pred_horizon: 1
obs_horizon: 1
action_horizon: 1


n_obs_steps: ${obs_horizon}
n_action_steps: ${action_horizon}

# Training parameters
num_epochs: 1000
model_path: ./weights/kitchen_mlp2_last.pt

train:
  loss:
    _target_: torch.nn.MSELoss


env_runner: 
  _target_: imitation.env_runner.robomimic_lowdim_runner.RobomimicEnvRunner
  output_dir: ${output_dir}
  env:
    _target_: imitation.env.robomimic_lowdim_wrapper.RobomimicLowdimWrapper
    task: "Lift"

policy:
  _target_: imitation.policy.mlp_policy.MLPPolicy
  model:
    _target_: imitation.model.mlp.MLPNet
    input_dim:  ${eval:'${obs_dim}*${pred_horizon}'}
    output_dim: ${eval:'${action_dim}*${action_horizon}'}
    hidden_dims: [256, 256, 256, 256, 256]
    activation:
      _target_: torch.nn.LeakyReLU
    output_activation: 
      _target_: torch.nn.Identity
  env: ${env_runner.env}
  # Diffusion Policy Dataset
  # dataset:
  #   _target_: diffusion_policy.dataset.kitchen_lowdim_dataset.KitchenLowdimDataset
  #   dataset_dir: ../diffusion_policy/data/kitchen/
  #   horizon: ${pred_horizon}
  #   pad_before: ${eval:'${n_obs_steps}-1'}
  #   pad_after: ${eval:'${n_action_steps}-1'}
  #   seed: 42
  #   val_ratio: 0.02
  # Relay Policy Dataset
  dataset:
    _target_: diffusion_policy.dataset.kitchen_mjl_lowdim_dataset.KitchenMjlLowdimDataset
    dataset_dir: ./data/kitchen_demos_multitask
    horizon: ${pred_horizon}
    pad_before: ${eval:'${n_obs_steps}-1'}
    pad_after: ${eval:'${n_action_steps}-1'}
    abs_action: true
    robot_noise_ratio: 0.1
    seed: 42
    val_ratio: 0.02


  # ckpt_path: ${model_path}


agent:
  _target_: imitation.agent.robomimic_lowdim_agent.RobomimicLowdimAgent

task_name: &task_name lift
dataset_type: &dataset_type ph
dataset_path: &dataset_path ./data/lift/${task.dataset_type}/low_dim_v141.hdf5

max_steps: 500


obs_keys: &obs_keys ['robot0_eef_pos', 'object']
action_keys: &action_keys ['robot0_joint_vel']

# describe all the objects in the scene
object_state_sizes: &object_state_sizes
  cube_pos: 3
  cube_quat: 4
  gripper_to_cube_pos: 3

# describe the object state keys that are used for the graph
object_state_keys: &object_state_keys
  cube: ["cube_pos", "cube_quat"]

env_runner:
  _target_: imitation.env_runner.robomimic_lowdim_runner.RobomimicEnvRunner
  output_dir: ${output_dir}
  action_horizon: ${action_horizon}
  obs_horizon: ${obs_horizon}
  render: ${render}
  output_video: ${output_video}
  env:
    _target_: imitation.env.robomimic_graph_wrapper.RobomimicGraphWrapper
    object_state_sizes: *object_state_sizes
    object_state_keys:  *object_state_keys
    max_steps: ${task.max_steps}
    task: "Lift"
    has_renderer: ${render}
    robots: ["Panda"]
    output_video: ${output_video}
    mode: ${task.dataset.mode}
dataset:
  _target_: imitation.dataset.robomimic_graph_dataset.RobomimicGraphDataset
  dataset_path: ${task.dataset_path}
  action_keys: *action_keys
  pred_horizon: ${pred_horizon}
  obs_horizon: ${obs_horizon}
  object_state_sizes: *object_state_sizes
  object_state_keys:  *object_state_keys
  mode: "joint-space"

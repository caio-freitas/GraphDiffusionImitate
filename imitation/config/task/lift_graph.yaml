
task_name: &task_name lift
dataset_type: &dataset_type ph
dataset_path: &dataset_path ./data/lift/${task.dataset_type}/low_dim_v141.hdf5

max_steps: ${eval:'600 if "${task.dataset_type}" == "mh" else 500'}

control_mode: "JOINT_VELOCITY"

obs_dim: 9
action_dim: 9

robots: ["Panda"]

# describe all the objects in the scene
object_state_sizes: &object_state_sizes
  cube_pos: 3
  cube_quat: 4
  gripper_to_cube_pos: 3

# describe the object state keys that are used for the graph
object_state_keys: &object_state_keys
  cube: ["cube_pos", "cube_quat"]

env_runner:
  _target_: imitation.env_runner.robomimic_lowdim_runner.RobomimicEnvRunner
  output_dir: ${output_dir}
  action_horizon: ${action_horizon}
  obs_horizon: ${obs_horizon}
  action_offset: ${action_offset}
  render: ${render}
  output_video: ${output_video}
  use_full_pred_after: 0.4 # after 40% of the steps, use full prediction
  env:
    _target_: imitation.env.robomimic_graph_wrapper.RobomimicGraphWrapper
    object_state_sizes: *object_state_sizes
    object_state_keys:  *object_state_keys
    max_steps: ${task.max_steps}
    task: "Lift"
    has_renderer: ${render}
    robots: ${task.robots}
    output_video: ${output_video}
    control_mode: ${task.control_mode}
    controller_config:
      interpolation: "linear"
      ramp_ratio: 0.2
    base_link_shift: [[-0.56, 0, 0.912]]
dataset:
  _target_: imitation.dataset.robomimic_graph_dataset.RobomimicGraphDataset
  dataset_path: ${task.dataset_path}
  robots: ${task.robots}
  pred_horizon: ${pred_horizon}
  obs_horizon: ${obs_horizon}
  object_state_sizes: *object_state_sizes
  object_state_keys:  *object_state_keys
  control_mode: ${task.control_mode}
  base_link_shift: [[-0.56, 0, 0.912]]
